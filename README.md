# Data-Lakes-with-Spark
will build a data lake and an ETL pipeline in Spark that loads data from S3, processes the data into analytics tables through Spark cluster hosted on AWS, and loads them back into S3. 

# Project Datasets
The same data of the Data Modeling projects have been used in this project

# Files Description
1- etl.py reads data from S3, processes that data using Spark, and writes them back to S3

2- dl.cfgcontains your AWS credentials

